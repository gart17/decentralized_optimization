{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('big'):\n",
    "    bar = tf.Variable(tf.zeros((10,10)))\n",
    "    with tf.name_scope('small'):\n",
    "        foo = tf.Variable(tf.zeros((10,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.Variable(initial_value=0)\n",
    "b = tf.identity(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.placeholder(shape=None, dtype=tf.float32)\n",
    "b = tf.identity(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run([a, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.26365563,  0.57871383],\n",
      "       [ 0.61935693,  0.92767334]], dtype=float32), array([[ 0.12059544,  0.60851705],\n",
      "       [ 0.8179093 ,  0.87373203]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=(2, 2))\n",
    "y = tf.identity(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    r1 = np.random.rand(2, 2)\n",
    "    r2 = np.random.rand(2, 2)\n",
    "    print(sess.run((x, y), feed_dict={x: r1, y: r2}))  # Will succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 Cost:  9.66667, W:  0.66667, b:      1.4\n",
      "  1 Cost:  0.14519, W:  0.81778, b:  1.45333\n",
      "  2 Cost:  0.03004, W:  0.80652, b:  1.43556\n",
      "  3 Cost:  0.02732, W:  0.81288, b:  1.42584\n",
      "  4 Cost:    0.026, W:  0.81719, b:  1.41552\n",
      "  5 Cost:  0.02477, W:  0.82161, b:  1.40554\n",
      "  6 Cost:  0.02359, W:  0.82589, b:  1.39579\n",
      "  7 Cost:  0.02247, W:  0.83008, b:  1.38627\n",
      "  8 Cost:   0.0214, W:  0.83416, b:  1.37699\n",
      "  9 Cost:  0.02039, W:  0.83815, b:  1.36793\n",
      " 10 Cost:  0.01942, W:  0.84204, b:  1.35908\n",
      " 11 Cost:   0.0185, W:  0.84584, b:  1.35045\n",
      " 12 Cost:  0.01762, W:  0.84954, b:  1.34202\n",
      " 13 Cost:  0.01678, W:  0.85316, b:   1.3338\n",
      " 14 Cost:  0.01598, W:  0.85669, b:  1.32578\n",
      " 15 Cost:  0.01523, W:  0.86013, b:  1.31795\n",
      " 16 Cost:   0.0145, W:   0.8635, b:   1.3103\n",
      " 17 Cost:  0.01381, W:  0.86678, b:  1.30284\n",
      " 18 Cost:  0.01316, W:  0.86998, b:  1.29556\n",
      " 19 Cost:  0.01253, W:  0.87311, b:  1.28846\n",
      " 20 Cost:  0.01194, W:  0.87616, b:  1.28152\n",
      " 21 Cost:  0.01137, W:  0.87913, b:  1.27476\n",
      " 22 Cost:  0.01083, W:  0.88204, b:  1.26815\n",
      " 23 Cost:  0.01032, W:  0.88488, b:  1.26171\n",
      " 24 Cost:  0.00983, W:  0.88764, b:  1.25541\n",
      " 25 Cost:  0.00936, W:  0.89034, b:  1.24927\n",
      " 26 Cost:  0.00891, W:  0.89298, b:  1.24328\n",
      " 27 Cost:  0.00849, W:  0.89555, b:  1.23743\n",
      " 28 Cost:  0.00809, W:  0.89806, b:  1.23173\n",
      " 29 Cost:   0.0077, W:  0.90051, b:  1.22616\n",
      " 30 Cost:  0.00734, W:  0.90291, b:  1.22072\n",
      " 31 Cost:  0.00699, W:  0.90524, b:  1.21541\n",
      " 32 Cost:  0.00666, W:  0.90752, b:  1.21023\n",
      " 33 Cost:  0.00634, W:  0.90974, b:  1.20518\n",
      " 34 Cost:  0.00604, W:  0.91191, b:  1.20025\n",
      " 35 Cost:  0.00575, W:  0.91403, b:  1.19543\n",
      " 36 Cost:  0.00548, W:  0.91609, b:  1.19074\n",
      " 37 Cost:  0.00522, W:  0.91811, b:  1.18615\n",
      " 38 Cost:  0.00497, W:  0.92008, b:  1.18168\n",
      " 39 Cost:  0.00473, W:    0.922, b:  1.17731\n",
      " 40 Cost:  0.00451, W:  0.92388, b:  1.17305\n",
      " 41 Cost:   0.0043, W:  0.92571, b:  1.16889\n",
      " 42 Cost:  0.00409, W:  0.92749, b:  1.16483\n",
      " 43 Cost:   0.0039, W:  0.92924, b:  1.16086\n",
      " 44 Cost:  0.00371, W:  0.93094, b:    1.157\n",
      " 45 Cost:  0.00354, W:   0.9326, b:  1.15322\n",
      " 46 Cost:  0.00337, W:  0.93422, b:  1.14954\n",
      " 47 Cost:  0.00321, W:   0.9358, b:  1.14594\n",
      " 48 Cost:  0.00306, W:  0.93734, b:  1.14244\n",
      " 49 Cost:  0.00291, W:  0.93885, b:  1.13901\n",
      " 50 Cost:  0.00277, W:  0.94032, b:  1.13567\n",
      " 51 Cost:  0.00264, W:  0.94175, b:  1.13241\n",
      " 52 Cost:  0.00252, W:  0.94315, b:  1.12923\n",
      " 53 Cost:   0.0024, W:  0.94452, b:  1.12612\n",
      " 54 Cost:  0.00228, W:  0.94585, b:  1.12309\n",
      " 55 Cost:  0.00217, W:  0.94716, b:  1.12013\n",
      " 56 Cost:  0.00207, W:  0.94843, b:  1.11724\n",
      " 57 Cost:  0.00197, W:  0.94967, b:  1.11442\n",
      " 58 Cost:  0.00188, W:  0.95088, b:  1.11167\n",
      " 59 Cost:  0.00179, W:  0.95206, b:  1.10899\n",
      " 60 Cost:   0.0017, W:  0.95321, b:  1.10637\n",
      " 61 Cost:  0.00162, W:  0.95433, b:  1.10381\n",
      " 62 Cost:  0.00155, W:  0.95543, b:  1.10132\n",
      " 63 Cost:  0.00147, W:   0.9565, b:  1.09888\n",
      " 64 Cost:   0.0014, W:  0.95755, b:   1.0965\n",
      " 65 Cost:  0.00134, W:  0.95857, b:  1.09418\n",
      " 66 Cost:  0.00127, W:  0.95956, b:  1.09192\n",
      " 67 Cost:  0.00121, W:  0.96054, b:  1.08971\n",
      " 68 Cost:  0.00115, W:  0.96149, b:  1.08755\n",
      " 69 Cost:   0.0011, W:  0.96241, b:  1.08545\n",
      " 70 Cost:  0.00105, W:  0.96332, b:  1.08339\n",
      " 71 Cost:    0.001, W:   0.9642, b:  1.08139\n",
      " 72 Cost:  0.00095, W:  0.96506, b:  1.07943\n",
      " 73 Cost:  0.00091, W:   0.9659, b:  1.07752\n",
      " 74 Cost:  0.00086, W:  0.96672, b:  1.07566\n",
      " 75 Cost:  0.00082, W:  0.96752, b:  1.07384\n",
      " 76 Cost:  0.00078, W:   0.9683, b:  1.07207\n",
      " 77 Cost:  0.00075, W:  0.96906, b:  1.07033\n",
      " 78 Cost:  0.00071, W:   0.9698, b:  1.06864\n",
      " 79 Cost:  0.00068, W:  0.97053, b:  1.06699\n",
      " 80 Cost:  0.00064, W:  0.97124, b:  1.06538\n",
      " 81 Cost:  0.00061, W:  0.97193, b:  1.06381\n",
      " 82 Cost:  0.00058, W:   0.9726, b:  1.06228\n",
      " 83 Cost:  0.00056, W:  0.97326, b:  1.06078\n",
      " 84 Cost:  0.00053, W:  0.97391, b:  1.05932\n",
      " 85 Cost:   0.0005, W:  0.97453, b:  1.05789\n",
      " 86 Cost:  0.00048, W:  0.97515, b:   1.0565\n",
      " 87 Cost:  0.00046, W:  0.97574, b:  1.05514\n",
      " 88 Cost:  0.00044, W:  0.97633, b:  1.05382\n",
      " 89 Cost:  0.00042, W:   0.9769, b:  1.05252\n",
      " 90 Cost:   0.0004, W:  0.97745, b:  1.05126\n",
      " 91 Cost:  0.00038, W:  0.97799, b:  1.05003\n",
      " 92 Cost:  0.00036, W:  0.97852, b:  1.04882\n",
      " 93 Cost:  0.00034, W:  0.97904, b:  1.04765\n",
      " 94 Cost:  0.00033, W:  0.97954, b:  1.04651\n",
      " 95 Cost:  0.00031, W:  0.98003, b:  1.04539\n",
      " 96 Cost:   0.0003, W:  0.98051, b:   1.0443\n",
      " 97 Cost:  0.00028, W:  0.98098, b:  1.04323\n",
      " 98 Cost:  0.00027, W:  0.98144, b:  1.04219\n",
      " 99 Cost:  0.00026, W:  0.98189, b:  1.04118\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [2, 3, 4]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "W = tf.Variable(2.)\n",
    "b = tf.Variable(2.)\n",
    "hypothesis = X * W + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "learning_rate = 0.1\n",
    "\n",
    "W_update = tf.assign(W, W - learning_rate * tf.gradients(cost, W)[0])\n",
    "b_update = tf.assign(b, b - learning_rate * tf.gradients(cost, b)[0])\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(100):\n",
    "    cost_val, W_update_val, b_update_val = sess.run(\n",
    "        [cost, W_update, b_update],\n",
    "        feed_dict={X: x_train, Y: y_train})\n",
    "    print(\"%3d Cost: %8s, W: %8s, b: %8s\" %\n",
    "          (step, round(cost_val, 5),\n",
    "            round(W_update_val, 5),\n",
    "            round(b_update_val, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
